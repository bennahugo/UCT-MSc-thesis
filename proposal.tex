\documentclass[a4paper,11pt,two column]{article}

\usepackage[utf8]{inputenc}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{mdframed}
\usepackage{color}
\usepackage{listing}
\usepackage{wrapfig}
\usepackage[parfill]{parskip}
\usepackage{subcaption}
\usepackage{hyperref}
\usepackage[font={small}]{caption}
\usepackage{marvosym}
\usepackage[margin=0.7in]{geometry}

\usepackage{tablefootnote}
\usepackage{abstract}
\usepackage{enumerate}
    \makeatletter
    \let\@fnsymbol\@arabic
    \makeatother
\begin{document}
\twocolumn[{
\centering
{\LARGE \textbf{GPU-accelerated facet-based convolutional gridding}}\\
{\large \textbf{The problem of non-coplanar widefield imaging in radio astronomy}}\\
Benjamin Hugo\thanks{bennahugo@aol.com}\\
Supervised by: James Gain\thanks{jgain@cs.uct.ac.za} and Oleg Smirnov\thanks{osmirnov@gmail.com}\\[0.5cm]
}]
\saythanks
\section{Introduction}
\subsection{Context}
Modern radio astronomy observes electromagnetic emissions from black bodies and magnetic processes with wavelengths typically around one million times longer than that of visible light, and is subsequently 
able to observe phenonma that is invisible at the wavelengths of visible light. Since its birth in the early 20th century, research has been largely driven towards building telescopes with higher resolving capability. Modern radio astronomy, for the most part, places a large emphasis on aperture synthesis. In essence this process combines the collecting capacity of many smaller apertures to provide an equivalent
resolving capability to that of a single very large aperture \cite{christiansenradiotelescopes}. 

Each antennae pair in such an array samples the sky in the fourier domain, and an image of the sky can be obtained through fourier inversion. One technique commonly employed is that of convolutional gridding and 
fast fourier transforms. This approach is typically about two orders of magnitude faster than computing each image pixel directly \cite[Lecture 7]{taylor1999synthesis}, especially when considering large visibility datasets. As telescope arrays grow larger, 
the size of these datasets grow quadratically with the number of elements of the array. Coupled with the problems of telescope calibration and image deconvolution, through several cycles of convolutional gridding and degridding, 
accelerating the imaging process is of vital importance in large arrays such as LOFAR and the Square Kilometer Array.

Both convolutional gridding and its inverse, convolutional degridding, can be parallelized and is suitable for processing on massively multicore architectures such as General Purpose GPUs. Although convolutional gridding 
has been implemented on GPUs in past research (for example \cite{romein2012efficient}), the grid sizes required by the Square Kilometer Array cannot easily be fitted in the onboard memory of current GPU accelerators. This problem can be mittigated by facet-based
imaging, where each image is split into multiple smaller facets, and computed independently of eachother. When combined these facets give an approximation to the celestrial sphere. 

Two additional benefits to faceting are the removal of time-invariant (or slowly variant) directionally dependent effects and the effects introduced by widefield non-coplanar baselines imaging \cite{cornwell1992radio,2011A&A...527A.107S}. The slow varying directional dependent effects, 
such as those introduced by the ionosphere and antenna beam patterns can be approximated for small facets and subsequently removed. The fourier relationship between the observed visibilities and true sky is additionally only defined for images over a small regions of the celestial sphere. 
Imaging wider fields of view introduces distortions in the image, which are significantly worsened when the observing antennae are not coplanar. Large two-dimensional arrays such as the Square Kilometer Array suffers from these distortions and requires the use of facets, snapshotting or 
w-projection (or any combination of these). Although facet-based imaging may be slower than w-projection, it has more flexible memory requirements, and may be of greater use to the Square Kilometer Array.
\subsection{Aims}
Our research aims to achieve two key objectives:
\begin{enumerate}[i)]
 \item \textbf{Implement an optimized CPU-based faceted convolutional gridder in C++}\\
  This will be achieved using OpenMP and AVX vector intrinsics where applicable. It will serve as a reasonable baseline for performance comparisons of a GPU-based version and previous research.
 \item \textbf{Implement a GPU-based faceted convolutional grider in CUDA}\\
  The GPU version will be based on the most work-efficient GPU gridding algorithm in the literature, but will modified to include faceting instead of w-projection.
\end{enumerate}

\subsection{Research question}
 
\section{Literature review}

\section{Procedures and methodology}
\subsection{Research design}
\subsection{Data sources}
\subsection{Validity}
 To ensure that the images produced by our gridder are correct they will be compared to the dirty images produced by well-known radio imaging toolsets, such as the Common Astronomy Software 
 Applications (CASA) \footnote{Freely available form \url{casa.nrao.edu}}.
 Literature on faceting is scarce in comparison to approaches such as W-projection, necessitating this first step.
\subsection{Resources required}
 
\section{Work plan}
\bibliography{proposal}
\bibliographystyle{plain}
\end{document}
